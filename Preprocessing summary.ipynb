{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "import sqlite3    ## SQL Interface\n",
    "import pickle     ## Used to save your data - Converts objects to byte stream and vice versa\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer  ## BOW Model\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer  ## TFIDF Model\n",
    "\n",
    "from sklearn.manifold import TSNE    ## To visualize high dimensional data\n",
    "\n",
    "## Modules to perform Text Preprocessing\n",
    "import re\n",
    "import nltk\n",
    "from nltk.stem.snowball import SnowballStemmer as sno\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import gensim    ## To build Word2Vec model\n",
    "\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>ProfileName</th>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <th>Score</th>\n",
       "      <th>Time</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>B001E4KFG0</td>\n",
       "      <td>A3SGXH7AUHU8GW</td>\n",
       "      <td>delmartian</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1303862400</td>\n",
       "      <td>Good Quality Dog Food</td>\n",
       "      <td>I have bought several of the Vitality canned d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>B00813GRG4</td>\n",
       "      <td>A1D87F6ZCVE5NK</td>\n",
       "      <td>dll pa</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1346976000</td>\n",
       "      <td>Not as Advertised</td>\n",
       "      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>B000LQOCH0</td>\n",
       "      <td>ABXLMWJIXXAIN</td>\n",
       "      <td>Natalia Corres \"Natalia Corres\"</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1219017600</td>\n",
       "      <td>\"Delight\" says it all</td>\n",
       "      <td>This is a confection that has been around a fe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>B000UA0QIQ</td>\n",
       "      <td>A395BORC6FGVXV</td>\n",
       "      <td>Karl</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1307923200</td>\n",
       "      <td>Cough Medicine</td>\n",
       "      <td>If you are looking for the secret ingredient i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>B006K2ZZ7K</td>\n",
       "      <td>A1UQRSCLF8GW1T</td>\n",
       "      <td>Michael D. Bigham \"M. Wassir\"</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1350777600</td>\n",
       "      <td>Great taffy</td>\n",
       "      <td>Great taffy at a great price.  There was a wid...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id   ProductId          UserId                      ProfileName  \\\n",
       "0   1  B001E4KFG0  A3SGXH7AUHU8GW                       delmartian   \n",
       "1   2  B00813GRG4  A1D87F6ZCVE5NK                           dll pa   \n",
       "2   3  B000LQOCH0   ABXLMWJIXXAIN  Natalia Corres \"Natalia Corres\"   \n",
       "3   4  B000UA0QIQ  A395BORC6FGVXV                             Karl   \n",
       "4   5  B006K2ZZ7K  A1UQRSCLF8GW1T    Michael D. Bigham \"M. Wassir\"   \n",
       "\n",
       "   HelpfulnessNumerator  HelpfulnessDenominator  Score        Time  \\\n",
       "0                     1                       1      5  1303862400   \n",
       "1                     0                       0      1  1346976000   \n",
       "2                     1                       1      4  1219017600   \n",
       "3                     3                       3      2  1307923200   \n",
       "4                     0                       0      5  1350777600   \n",
       "\n",
       "                 Summary                                               Text  \n",
       "0  Good Quality Dog Food  I have bought several of the Vitality canned d...  \n",
       "1      Not as Advertised  Product arrived labeled as Jumbo Salted Peanut...  \n",
       "2  \"Delight\" says it all  This is a confection that has been around a fe...  \n",
       "3         Cough Medicine  If you are looking for the secret ingredient i...  \n",
       "4            Great taffy  Great taffy at a great price.  There was a wid...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using the SQLite Table to read data.\n",
    "conn = sqlite3.connect('database.sqlite')\n",
    "\n",
    "#filtering only positive and negative reviews i.e. \n",
    "# not taking into consideration those reviews with Score=3\n",
    "filtered_data = pd.read_sql_query(\"\"\"\n",
    "SELECT *\n",
    "FROM Reviews\n",
    "WHERE Score != 3\n",
    "\"\"\", conn)\n",
    "\n",
    "conn.close()\n",
    "\n",
    "filtered_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def partition(x):\n",
    "    if x < 3:\n",
    "        return 0\n",
    "    return 1\n",
    "\n",
    "## Pandas Series have a map function which apply function object to all the elements\n",
    "filtered_data['Score'] = filtered_data['Score'].map(partition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(364173, 10)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final = filtered_data.drop_duplicates(subset = {\"UserId\",\"ProfileName\",\"Time\",\"Text\"})   #Removing all the duplicate entries in the DataFrame.\n",
    "final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(364171, 10)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final=final[final.HelpfulnessNumerator<=final.HelpfulnessDenominator]  \n",
    "final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stop = set(stopwords.words('english')) #set of stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'where', \"isn't\", 'him', 'were', 'at', 'again', 've', 'be', \"don't\", 'other', 'no', 's', \"couldn't\", 'with', \"doesn't\", 'his', \"you'll\", \"you've\", 't', 'that', 'down', 'further', 'more', 'such', 'only', 'here', \"needn't\", 'before', \"hasn't\", 'we', \"you'd\", 'whom', 'having', 'couldn', 'this', 'of', \"won't\", 'does', 'you', 'had', 'just', \"shouldn't\", 'am', 'them', 'or', 'during', 'a', 'hadn', 'up', 'as', 'if', \"hadn't\", 'hasn', 'each', 'what', 'why', \"wasn't\", 'ain', 'hers', 'very', 'because', 'when', 'being', 'over', \"wouldn't\", 'after', 'below', 'these', 'has', 'in', 'once', 'shouldn', 'is', 'myself', 'itself', 'mustn', 'shan', 'me', 'ourselves', 'which', 'herself', \"aren't\", 'above', \"shan't\", 'ours', 'he', \"mightn't\", 'will', 'don', 'y', 'now', 'then', 'your', 'an', 'm', 'they', 'doing', 'didn', 'but', 'haven', 'ma', 'its', 'those', 'was', 'by', \"weren't\", 'between', 'into', 'most', 'any', 'under', 'wasn', 'how', 'her', \"that'll\", 'are', 'o', 'she', 're', 'doesn', 'themselves', 'needn', 'do', 'out', 'should', \"you're\", 'from', 'off', 'than', \"it's\", 'for', \"she's\", \"haven't\", 'yourself', 'can', 'and', \"should've\", 'yourselves', 'some', 'few', 'own', 'weren', 'so', 'all', 'been', 'theirs', 'd', \"didn't\", 'our', 'it', 'yours', 'll', 'mightn', \"mustn't\", 'wouldn', 'himself', 'through', 'about', 'who', 'while', 'too', 'my', 'did', 'both', 'i', 'their', 'same', 'aren', 'there', 'until', 'to', 'have', 'isn', 'on', 'the'}\n"
     ]
    }
   ],
   "source": [
    "lst = ['won', 'nor', 'not', 'against']  #Removing the words meaning negation from stopwords as it is fundamental for the analysis\n",
    "for word in lst:\n",
    "    stop.remove(word)\n",
    "print(stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cleanhtml(sentence):\n",
    "    '''This function removes all the html tags in the given sentence'''\n",
    "    cleanr = re.compile('<.*?>')    ## find the index of the html tags\n",
    "    cleantext = re.sub(cleanr, ' ', sentence)  ## Substitute <space> in place of any html tag\n",
    "    return cleantext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cleanpunc(sentence):\n",
    "    '''This function cleans all the punctuation or special characters from a given sentence'''\n",
    "    cleaned = re.sub(r'[?|@|!|^|%|\\'|\"|#]',r'',sentence)\n",
    "    cleaned = re.sub(r'[.|,|)|(|\\|/]',r' ',cleaned)\n",
    "    return  cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocessing(series):\n",
    "    '''The function takes a Pandas Series object containing text in all the cells\n",
    "       And performs following Preprocessing steps on each cell:\n",
    "       1. Clean text from html tags\n",
    "       2. Clean text from punctuations and special characters\n",
    "       3. Retain only non-numeric Latin characters with lenght > 2\n",
    "       4. Remove stopwords from the sentence\n",
    "       5. Apply stemming to all the words in the sentence\n",
    "       \n",
    "       Return values:\n",
    "       1. final_string - List of cleaned sentences\n",
    "       2. list_of_sent - List of lists which can be used as input to the W2V model'''\n",
    "    \n",
    "    i = 0\n",
    "    str1=\" \"\n",
    "    final_string = []    ## This list will contain cleaned sentences\n",
    "    list_of_sent = []    ## This is a list of lists used as input to the W2V model at a later stage\n",
    "    #sno = SnowballStemmer(\"english\")\n",
    "    \n",
    "    ## Creating below lists for future use\n",
    "    all_positive_words=[] # store words from +ve reviews here\n",
    "    all_negative_words=[] # store words from -ve reviews here\n",
    "    \n",
    "    \n",
    "    for sent in series.values:\n",
    "        ## \n",
    "        filtered_sent = []\n",
    "        sent = cleanhtml(sent)    ## Clean the HTML tags\n",
    "        sent = cleanpunc(sent)    ## Clean the punctuations and special characters\n",
    "        ## Sentences are cleaned and words are handled individually\n",
    "        for cleaned_words in sent.split():\n",
    "            ## Only consider non-numeric words with length at least 3\n",
    "            if((cleaned_words.isalpha()) and (len(cleaned_words) > 2)):\n",
    "                ## Only consider words which are not stopwords and convert them to lowet case\n",
    "                if(cleaned_words.lower() not in stop):\n",
    "                    ## Apply snowball stemmer and add them to the filtered_sent list\n",
    "                    #s = (sno.stem(cleaned_words.lower()))#.encode('utf-8')\n",
    "                    filtered_sent.append(cleaned_words.lower())    ## This contains all the cleaned words for a sentence\n",
    "                    ''''\n",
    "                    if (final['Score'].values)[i] == 1:\n",
    "                        all_positive_words.append(s) #list of all words used to describe positive reviews\n",
    "                    if(final['Score'].values)[i] == 0:\n",
    "                        all_negative_words.append(s) #list of all words used to describe negative reviews\n",
    "                    '''\n",
    "        ## Below list is a list of lists used as input to W2V model later\n",
    "        list_of_sent.append(filtered_sent)\n",
    "        ## Join back all the words belonging to the same sentence\n",
    "        str1 = \" \".join(filtered_sent)\n",
    "        ## Finally add the cleaned sentence in the below list\n",
    "        final_string.append(str1)\n",
    "        #print(i)\n",
    "        i += 1\n",
    "    return final_string, list_of_sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final_string, list_of_sent = preprocessing(final['Summary'])  #Preprocessing the 'Text' column in the DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final['Summary_Cleaned']=final_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Id</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>ProfileName</th>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <th>Score</th>\n",
       "      <th>Time</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "      <th>CleanedText_NoStem</th>\n",
       "      <th>CleanedText_Stemmed</th>\n",
       "      <th>Summary_Cleaned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>253564</th>\n",
       "      <td>343681</td>\n",
       "      <td>89476</td>\n",
       "      <td>B0014WYXQK</td>\n",
       "      <td>A1WXFL6IXQKAM5</td>\n",
       "      <td>Barb Caffrey \"writer-for-hire\"</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1208908800</td>\n",
       "      <td>Tart, but good</td>\n",
       "      <td>Izze's All-Natural Sparkling Pomegranate Juice...</td>\n",
       "      <td>izzes sparkling pomegranate juice good tart ju...</td>\n",
       "      <td>izz sparkl pomegran juic good tart juic tast g...</td>\n",
       "      <td>tart good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123620</th>\n",
       "      <td>148757</td>\n",
       "      <td>232613</td>\n",
       "      <td>B000E243RA</td>\n",
       "      <td>A3EGPIZHPZ4Z4N</td>\n",
       "      <td>vegasmama \"Angelgirl\"</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1347840000</td>\n",
       "      <td>Heavenly</td>\n",
       "      <td>Saw these online thought something different. ...</td>\n",
       "      <td>saw online thought something different healthy...</td>\n",
       "      <td>saw onlin thought someth differ healthi tasti ...</td>\n",
       "      <td>heavenly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111670</th>\n",
       "      <td>132523</td>\n",
       "      <td>14254</td>\n",
       "      <td>B0045XE32E</td>\n",
       "      <td>A3OSHB0AACYN95</td>\n",
       "      <td>Tom Tracy</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1302048000</td>\n",
       "      <td>My Four Medium - Large Dogs Love Them!</td>\n",
       "      <td>These \"certified organic\" (by Oregon Tilth) ba...</td>\n",
       "      <td>certified organic oregon tilth baked dog treat...</td>\n",
       "      <td>certifi organ oregon tilth bake dog treat made...</td>\n",
       "      <td>four medium large dogs love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91849</th>\n",
       "      <td>106421</td>\n",
       "      <td>66426</td>\n",
       "      <td>B001JKGQHQ</td>\n",
       "      <td>AGJ80C07WF11Z</td>\n",
       "      <td>pinjam</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1297900800</td>\n",
       "      <td>By far the best chocolate</td>\n",
       "      <td>I first had these chocolates over 20 years ago...</td>\n",
       "      <td>first chocolates years ago mom would bring bac...</td>\n",
       "      <td>first chocol year ago mom would bring back wou...</td>\n",
       "      <td>far best chocolate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155724</th>\n",
       "      <td>194252</td>\n",
       "      <td>293177</td>\n",
       "      <td>B003YVMUFK</td>\n",
       "      <td>A27VBMB8NNKEJU</td>\n",
       "      <td>A. Patterson</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1308441600</td>\n",
       "      <td>My dogs really like it</td>\n",
       "      <td>I needed a grain free canned dog food (to mix ...</td>\n",
       "      <td>needed grain free canned dog food mix grain fr...</td>\n",
       "      <td>need grain free can dog food mix grain free dr...</td>\n",
       "      <td>dogs really like</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         index      Id   ProductId          UserId  \\\n",
       "253564  343681   89476  B0014WYXQK  A1WXFL6IXQKAM5   \n",
       "123620  148757  232613  B000E243RA  A3EGPIZHPZ4Z4N   \n",
       "111670  132523   14254  B0045XE32E  A3OSHB0AACYN95   \n",
       "91849   106421   66426  B001JKGQHQ   AGJ80C07WF11Z   \n",
       "155724  194252  293177  B003YVMUFK  A27VBMB8NNKEJU   \n",
       "\n",
       "                           ProfileName  HelpfulnessNumerator  \\\n",
       "253564  Barb Caffrey \"writer-for-hire\"                     0   \n",
       "123620           vegasmama \"Angelgirl\"                     0   \n",
       "111670                       Tom Tracy                     0   \n",
       "91849                           pinjam                     1   \n",
       "155724                    A. Patterson                     3   \n",
       "\n",
       "        HelpfulnessDenominator  Score        Time  \\\n",
       "253564                       0      1  1208908800   \n",
       "123620                       0      1  1347840000   \n",
       "111670                       0      1  1302048000   \n",
       "91849                        2      1  1297900800   \n",
       "155724                       3      1  1308441600   \n",
       "\n",
       "                                       Summary  \\\n",
       "253564                          Tart, but good   \n",
       "123620                                Heavenly   \n",
       "111670  My Four Medium - Large Dogs Love Them!   \n",
       "91849                By far the best chocolate   \n",
       "155724                  My dogs really like it   \n",
       "\n",
       "                                                     Text  \\\n",
       "253564  Izze's All-Natural Sparkling Pomegranate Juice...   \n",
       "123620  Saw these online thought something different. ...   \n",
       "111670  These \"certified organic\" (by Oregon Tilth) ba...   \n",
       "91849   I first had these chocolates over 20 years ago...   \n",
       "155724  I needed a grain free canned dog food (to mix ...   \n",
       "\n",
       "                                       CleanedText_NoStem  \\\n",
       "253564  izzes sparkling pomegranate juice good tart ju...   \n",
       "123620  saw online thought something different healthy...   \n",
       "111670  certified organic oregon tilth baked dog treat...   \n",
       "91849   first chocolates years ago mom would bring bac...   \n",
       "155724  needed grain free canned dog food mix grain fr...   \n",
       "\n",
       "                                      CleanedText_Stemmed  \\\n",
       "253564  izz sparkl pomegran juic good tart juic tast g...   \n",
       "123620  saw onlin thought someth differ healthi tasti ...   \n",
       "111670  certifi organ oregon tilth bake dog treat made...   \n",
       "91849   first chocol year ago mom would bring back wou...   \n",
       "155724  need grain free can dog food mix grain free dr...   \n",
       "\n",
       "                    Summary_Cleaned  \n",
       "253564                    tart good  \n",
       "123620                     heavenly  \n",
       "111670  four medium large dogs love  \n",
       "91849            far best chocolate  \n",
       "155724             dogs really like  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open ('list_of_sent_summary.pkl','wb') as pickle_file:\n",
    "    pickle.dump(list_of_sent, pickle_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = sqlite3.connect('final2.sqlite')    #Saving the changes made above into a new sqlite file\n",
    "c=conn.cursor()\n",
    "final.to_sql('Reviews', conn, if_exists='replace')\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
